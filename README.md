# Hand-sign-recognition
An end-to-end computer vision and deep learning project that recognizes hand sign alphabets (Aâ€“Z) in real time using a webcam and converts them into text and speech, enabling accessible humanâ€“computer interaction.

ğŸ” Project Objective

The objective of this project is to design and implement a real-time hand sign recognition system that can:

Detect hand gestures using a webcam

Recognize sign language alphabets (Aâ€“Z)

Convert continuous gestures into readable words

Generate speech output from recognized text

This project demonstrates a complete AI pipeline â€” from data collection and preprocessing to model training and real-time deployment.

ğŸ§© Dataset Description

The dataset is custom-built using a webcam and contains hand gesture images representing alphabets A to Z.

Dataset characteristics:

Alphabet-based gesture images (Aâ€“Z)

Images captured under different lighting and angles

Class-wise organization for each alphabet

Dataset collected manually to simulate real-world conditions

âš ï¸ The dataset is not included in the repository due to size limitations and can be recreated using the data collection script.

ğŸ› ï¸ Tools & Technologies Used

Python â€” core programming language

OpenCV â€” real-time video capture and image processing

MediaPipe â€” hand landmark detection and tracking

TensorFlow / Keras â€” CNN model development and training

NumPy â€” numerical computation

SpeechRecognition â€” speech-to-text input

pyttsx3 â€” text-to-speech conversion

GitHub â€” version control and project hosting

ğŸ§ª Data Collection & Preparation

Hand gesture images collected using webcam

Images organized class-wise (Aâ€“Z)

Dataset validated for consistency and labeling accuracy

Preprocessed images resized and normalized before training

Separate scripts used for data collection and preprocessing

ğŸ§  Model Development

Model Type: Convolutional Neural Network (CNN)

Input: Hand images / hand landmarks

Output: Alphabet class (Aâ€“Z)

Model trained on the custom dataset

Achieved high training accuracy

The trained model is then integrated into a real-time prediction pipeline.

ğŸ¥ Real-Time Gesture Recognition

The real-time system performs the following steps:

Captures video frames using webcam

Detects hand landmarks using MediaPipe

Extracts features from detected hand

Predicts the corresponding alphabet

Displays prediction on screen

Forms words from continuous predictions

Converts final text into speech

ğŸ® Application Controls
Action	Input
Show hand gesture	Detect alphabet
V key	Speak a letter using voice input
S key	Speak the complete word
ESC key	Exit the application
ğŸ“Š Results & Observations

The system successfully recognizes most alphabet gestures in real time

Prediction accuracy varies depending on:

Lighting conditions

Hand orientation

Similarity between gestures

Some letters with similar hand shapes may cause minor misclassification

Despite these challenges, the system performs reliably under controlled conditions.

âš ï¸ Limitations

Similar-looking gestures (e.g., M, N, S, T) are harder to distinguish

Performance depends on camera quality and lighting

Dataset collected from limited users affects generalization

Real-time predictions may fluctuate frame-to-frame

These limitations are common in real-time sign language recognition systems.

ğŸŒ± Future Enhancements

Support for numbers (0â€“9)

Sentence-level sign recognition

Dictionary-based word correction

Multi-user dataset for improved accuracy

Web or mobile application deployment

ğŸ“‚ Repository Structure
hand-sign-recognition/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ train_model.py        # Model training script
â”‚   â”œâ”€â”€ predict_sign.py       # Real-time prediction script
â”‚   â””â”€â”€ voice.py              # Speech input/output
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ .gitignore

ğŸ“ Learning Outcomes

Practical experience with Computer Vision

Understanding real-time ML system constraints

End-to-end deep learning pipeline implementation

Integration of vision, ML, and speech technologies

Debugging and optimizing real-world AI applications

ğŸ“œ License

This project is licensed under the MIT License.

âœ… Final Note

This project showcases a complete real-time AI application, highlighting both the capabilities and challenges of hand sign recognition systems and demonstrating strong problem-solving, implementation, and debugging skills.
## âœï¸ Author  

**Gopika Pushpan**  
B.Tech Computer Science | AI & Machine Learning Enthusiast
